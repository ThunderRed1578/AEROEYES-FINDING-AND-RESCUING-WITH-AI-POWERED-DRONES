{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13557915,"sourceType":"datasetVersion","datasetId":8611691},{"sourceId":13563608,"sourceType":"datasetVersion","datasetId":8615623}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle URL: [Yolo11s Augmentation Dataset Creation](https://www.kaggle.com/code/phatle1578/yolo11s-augmentation-dataset-creation)","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# 1Ô∏è‚É£ C√ÄI ƒê·∫∂T M√îI TR∆Ø·ªúNG (ƒê√É FIX RAY + TENSORBOARD)\n# ====================================================\n!pip uninstall -y ray ray[default] ray[tune] >/dev/null 2>&1 || true\n!pip -q install ultralytics==8.3.27 opencv-contrib-python==4.10.0.84 tqdm==4.67.1 torch==2.1.2 torchvision==0.16.2 open_clip_torch==2.24.0 timm==0.9.12 # (P) add last library\n# üîß FIX l·ªói TensorBoard / protobuf conflict\n!pip install -q \"numpy<2.0\"\n!pip install -q protobuf==3.20.3 tensorboard==2.14.0\n!pip install -q filterpy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================\n# 2Ô∏è‚É£ CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n# ====================================================\nimport os, re, json, shutil, random, cv2\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_ROOT = Path(\"/kaggle/input/train-zaic-dl\")\nANN_PATH = Path(\"/kaggle/input/annotation/annotations.json\")\nWORK_DIR = Path(\"/kaggle/working/zaic_yolo\")\n\nYOLO_IMG_DIR_TR = WORK_DIR/\"yolo_dataset/images/train\"\nYOLO_IMG_DIR_VA = WORK_DIR/\"yolo_dataset/images/val\"\nYOLO_LBL_DIR_TR = WORK_DIR/\"yolo_dataset/labels/train\"\nYOLO_LBL_DIR_VA = WORK_DIR/\"yolo_dataset/labels/val\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for p in [YOLO_IMG_DIR_TR, YOLO_IMG_DIR_VA, YOLO_LBL_DIR_TR, YOLO_LBL_DIR_VA]:\n    p.mkdir(parents=True, exist_ok=True)\n\n# Load annotations\nwith open(ANN_PATH, \"r\") as f:\n    ann_json = json.load(f)\n\nvideo_to_frame_bboxes = {}\nann_list = [ann_json] if isinstance(ann_json, dict) and \"video_id\" in ann_json else ann_json\nfor item in ann_list:\n    vid = item[\"video_id\"]\n    video_to_frame_bboxes.setdefault(vid, {})\n    for ann in item.get(\"annotations\", []):\n        for bb in ann.get(\"bboxes\", []):\n            fr = int(bb[\"frame\"])\n            video_to_frame_bboxes[vid].setdefault(fr, []).append([bb[\"x1\"], bb[\"y1\"], bb[\"x2\"], bb[\"y2\"]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Utils\nnum_re = re.compile(r\"(\\d+)\")\ndef extract_frame_index(filename: str):\n    nums = num_re.findall(Path(filename).stem)\n    return int(nums[-1]) if nums else None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_yolo_line(x1,y1,x2,y2, W,H, cls=0):\n    x1, y1 = max(0, x1), max(0, y1)\n    x2, y2 = min(W-1, x2), min(H-1, y2)\n    w = max(1, x2 - x1); h = max(1, y2 - y1)\n    cx = x1 + w/2; cy = y1 + h/2\n    return f\"{cls} {cx/W:.6f} {cy/H:.6f} {w/W:.6f} {h/H:.6f}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split train/val\ns_dirs = sorted([p for p in TRAIN_ROOT.iterdir() if p.is_dir()])\nrandom.seed(42)\nrandom.shuffle(s_dirs)\nsplit = int(0.9 * len(s_dirs))\ntrain_s = set(p.name for p in s_dirs[:split])\nval_s = set(p.name for p in s_dirs[split:])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert frames ‚Üí YOLO\ndef process_split(s_name, img_out_dir, lbl_out_dir):\n    s_path = TRAIN_ROOT/s_name/\"object_frames\"\n    if not s_path.exists(): return\n    img_files = sorted(list(s_path.glob(\"*.jpg\")))\n    frame_to_file = {extract_frame_index(f.name): f for f in img_files if extract_frame_index(f.name) is not None}\n    ann_frames = video_to_frame_bboxes.get(s_name, {})\n    for fr, bboxes in ann_frames.items():\n        if fr not in frame_to_file: continue\n        src_img = frame_to_file[fr]\n        img = cv2.imread(str(src_img))\n        if img is None: continue\n        H, W = img.shape[:2]\n        lbl_path = lbl_out_dir / (src_img.stem + \".txt\")\n        with open(lbl_path, \"w\") as f:\n            f.write(\"\\n\".join([to_yolo_line(*bb, W,H, cls=0) for bb in bboxes]))\n        shutil.copy2(src_img, img_out_dir/src_img.name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"REID_ROOT = WORK_DIR / \"reid_dataset\"\nREID_ROOT.mkdir(parents=True, exist_ok=True)\nprint(f\"üîπ B·∫Øt ƒë·∫ßu t·∫°o Re-ID dataset t·∫°i: {REID_ROOT}\")\n\nnum_classes_reid = 0\nclass_map_reid = {}\n\n# Ch·ªâ d√πng c√°c video trong t·∫≠p train\nfor s_name in tqdm(train_s, desc=\"Processing Re-ID dataset\"):\n    s_path_frames = TRAIN_ROOT / s_name / \"object_frames\"\n    if not s_path_frames.exists():\n        continue\n\n    # √Ånh x·∫° t√™n video sang label s·ªë\n    if s_name not in class_map_reid:\n        class_map_reid[s_name] = num_classes_reid\n        num_classes_reid += 1\n    label_id = class_map_reid[s_name]\n\n    # T·∫°o th∆∞ m·ª•c cho class n√†y\n    class_dir = REID_ROOT / str(label_id)\n    class_dir.mkdir(exist_ok=True)\n\n    # L·∫•y danh s√°ch file ·∫£nh\n    img_files = sorted(s_path_frames.glob(\"*.jpg\"))\n    frame_to_file = {\n        extract_frame_index(f.name): f\n        for f in img_files\n        if extract_frame_index(f.name) is not None\n    }\n\n    # L·∫•y bbox cho t·ª´ng frame\n    ann_frames = video_to_frame_bboxes.get(s_name, {})\n\n    img_count = 0\n    for fr, bboxes in ann_frames.items():\n        if fr not in frame_to_file:\n            continue\n\n        src_img_path = frame_to_file[fr]\n        img = cv2.imread(str(src_img_path))\n        if img is None:\n            continue\n\n        for i, bb in enumerate(bboxes):\n            x1, y1, x2, y2 = map(int, bb)\n            cropped_obj = img[y1:y2, x1:x2]\n\n            if cropped_obj.size > 0:\n                out_name = f\"{fr:04d}_{i}.jpg\"\n                cv2.imwrite(str(class_dir / out_name), cropped_obj)\n                img_count += 1\n\n    if img_count == 0:\n        print(f\"‚ö†Ô∏è Video {s_name} kh√¥ng c√≥ ·∫£nh crop n√†o ƒë∆∞·ª£c l∆∞u.\")\n\nprint(f\"‚úÖ T·∫°o Re-ID dataset ho√†n t·∫•t. T·ªïng c·ªông {num_classes_reid} classes.\")\n\n# L∆∞u s·ªë l∆∞·ª£ng class ƒë·ªÉ d√πng khi train\n%store num_classes_reid","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for s in tqdm(train_s, desc=\"Building YOLO train split\"):\n    process_split(s, YOLO_IMG_DIR_TR, YOLO_LBL_DIR_TR)\nfor s in tqdm(val_s, desc=\"Building YOLO val split\"):\n    process_split(s, YOLO_IMG_DIR_VA, YOLO_LBL_DIR_VA)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3Ô∏è‚É£ AUGMENTATION N√ÇNG CAO (FIX BUG)\n# ====================================================\ndef rand_bool(p): return random.random() < p","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Photometric augmentations ===\ndef jitter_hsv(img, dh=10, ds=40, dv=30, p=0.7):\n    if not rand_bool(p): return img\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.int32)\n    h,s,v = cv2.split(hsv)\n    h = (h + random.randint(-dh, dh)) % 180\n    s = np.clip(s + random.randint(-ds, ds), 0, 255)\n    v = np.clip(v + random.randint(-dv, dv), 0, 255)\n    hsv = cv2.merge([h.astype(np.uint8), s.astype(np.uint8), v.astype(np.uint8)])\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def brightness_contrast(img, p=0.7, b_lim=0.25, c_lim=0.25):\n    if not rand_bool(p): return img\n    alpha = 1.0 + random.uniform(-c_lim, c_lim)\n    beta = 255.0 * random.uniform(-b_lim, b_lim)\n    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def adjust_gamma(img, p=0.4, g_range=(0.8,1.3)):\n    if not rand_bool(p): return img\n    gamma = random.uniform(*g_range)\n    inv = 1.0 / gamma\n    table = ((np.arange(256)/255.0)**inv * 255).astype(np.uint8)\n    return cv2.LUT(img, table)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gaussian_noise(img, p=0.4, var=(5.0, 50.0)):\n    if not rand_bool(p): return img\n    sigma = np.sqrt(random.uniform(*var))\n    noise = np.random.normal(0, sigma, img.shape).astype(np.float32)\n    return np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def motion_blur(img, p=0.35):\n    if not rand_bool(p): return img\n    k = random.choice([5,7,9])\n    kernel = np.zeros((k,k), np.float32)\n    kernel[k//2, :] = 1.0\n    angle = random.uniform(0,180)\n    M = cv2.getRotationMatrix2D((k/2-0.5, k/2-0.5), angle, 1.0)\n    kernel = cv2.warpAffine(kernel, M, (k,k))\n    kernel /= (kernel.sum() + 1e-8)\n    return cv2.filter2D(img, -1, kernel)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clahe_lab(img, p=0.25):\n    if not rand_bool(p): return img\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    l,a,b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=random.uniform(2.0,4.0), tileGridSize=(8,8))\n    l = clahe.apply(l)\n    return cv2.cvtColor(cv2.merge([l,a,b]), cv2.COLOR_LAB2BGR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Geometric augmentations ===\ndef random_perspective(img, p=0.4):\n    if not rand_bool(p): return img\n    h, w = img.shape[:2]\n    src = np.float32([[0,0],[w,0],[w,h],[0,h]])\n    jitter = np.random.uniform(-0.1, 0.1, (4,2))\n    dst = src * (1 + jitter)\n    dst[:,0] = np.clip(dst[:,0], 0, w)\n    dst[:,1] = np.clip(dst[:,1], 0, h)\n    try:\n        M = cv2.getPerspectiveTransform(src, dst)\n        return cv2.warpPerspective(img, M, (w,h), borderMode=cv2.BORDER_REFLECT)\n    except cv2.error:\n        return img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_crop(img, p=0.4):\n    if not rand_bool(p): return img\n    h,w = img.shape[:2]\n    scale = random.uniform(0.7, 1.0)\n    nh, nw = int(h*scale), int(w*scale)\n    y1 = random.randint(0, h-nh)\n    x1 = random.randint(0, w-nw)\n    cropped = img[y1:y1+nh, x1:x1+nw]\n    return cv2.resize(cropped, (w,h))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_rotate(img, p=0.4):\n    if not rand_bool(p): return img\n    h, w = img.shape[:2]\n    angle = random.uniform(-10, 10)\n    M = cv2.getRotationMatrix2D((w/2,h/2), angle, 1)\n    return cv2.warpAffine(img, M, (w,h), borderMode=cv2.BORDER_REFLECT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === CutMix-like augmentation ===\ndef cutmix_pair(img1, img2, p=0.3):\n    if not rand_bool(p): return img1\n    h,w = img1.shape[:2]\n    x1, y1 = random.randint(0,w//2), random.randint(0,h//2)\n    x2, y2 = random.randint(w//2,w), random.randint(h//2,h)\n    img1[y1:y2, x1:x2] = img2[y1:y2, x1:x2]\n    return img1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def advanced_augment(img, pool=None):\n    img = jitter_hsv(img)\n    img = brightness_contrast(img)\n    img = adjust_gamma(img)\n    img = gaussian_noise(img)\n    img = motion_blur(img)\n    img = clahe_lab(img)\n    img = random_crop(img)\n    img = random_rotate(img)\n    img = random_perspective(img)\n    if pool:\n        img2 = random.choice(pool)\n        img = cutmix_pair(img, img2)\n    return img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_dataset(img_dir, lbl_dir, k=2):\n    imgs = sorted(Path(img_dir).glob(\"*.jpg\"))\n    pool = [cv2.imread(str(p)) for p in random.sample(imgs, min(10,len(imgs)))]\n    for p in tqdm(imgs, desc=f\"Augment++ {img_dir.name}\"):\n        lbl_path = Path(lbl_dir)/f\"{p.stem}.txt\"\n        if not lbl_path.exists(): continue\n        img = cv2.imread(str(p))\n        lbl_txt = lbl_path.read_text()\n        for i in range(k):\n            out = advanced_augment(img, pool)\n            out_name = f\"{p.stem}_augx{i}.jpg\"\n            cv2.imwrite(str(Path(img_dir)/out_name), out)\n            (Path(lbl_dir)/f\"{p.stem}_augx{i}.txt\").write_text(lbl_txt)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augment_dataset(YOLO_IMG_DIR_TR, YOLO_LBL_DIR_TR, k=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}